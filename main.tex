\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsfonts}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\realsgtzero}{\reals_{> 0}}
\newcommand{\complexes}{\mathbb{C}}

\usepackage{amsthm}
\usepackage{thmtools}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
%\newtheorem{definition}{Definition}
\declaretheorem[name=Definition,qed=\lower-0.3ex\hbox{\(\Diamond\)}]{definition}
%\newtheorem{example}{Example}
\declaretheorem[name=Example,qed={\lower-0.3ex\hbox{\(\triangle\)}}]{example}

\usepackage{mathtools}
\DeclarePairedDelimiter{\parensproto}{\lparen}{\rparen}
\newcommand{\parens}{\parensproto*}
\DeclarePairedDelimiter{\bracksproto}{\lbrack}{\rbrack}
\newcommand{\bracks}{\bracksproto*}
\DeclarePairedDelimiter{\lhalfopenproto}{\lparen}{\rbrack}
\newcommand{\lhalfopen}{\lhalfopenproto*}
\DeclarePairedDelimiter{\rhalfopenproto}{\lbrack}{\rparen}
\newcommand{\rhalfopen}{\rhalfopenproto*}
\DeclarePairedDelimiterX{\setbuilderproto}[2]{\lbrace}{\rbrace}{{#1}\,\middle|\,{#2}}
\newcommand{\setbuilder}{\setbuilderproto*}

\usepackage{commath}

\usepackage{hyperref}
\usepackage{cleveref}

\newcommand{\jacobian}[1]{D{#1}}
\newcommand{\orbit}[1]{O\parens{{#1}}}
\newcommand{\schwarzian}[1]{S\parens{#1}}

\begin{document}

\section{Discrete Dynamical Systems: A Review}

\subsection{One-Dimensional Maps}

A continuous-time first-order dynamical system is generated by a differential equation of the form
\[
  \frac{dx}{dt} = f(x, t).
\]
The discrete-time analogue of the differential is the difference, so we say that a discrete-time first-order dynamical system is generated by a \emph{difference equation} of the form
\[
  x_{t + 1} - x_t = f(x_t).
\]
The analogy with differential equations goes further: just as a differential equation cannot generally be solved without specifying a boundary coundtion, the value of \(x_t\) in a discrete-time dynamical system cannot generally be determined without specifying an initial condition; i.e., the value of \(x_0\).

We can move the \(x_t\) term to the right-hand side and absorb it into \(f\). Replacing \(t\) with \(n\) then yields the more common form
\[
  x_{n + 1} = f(x_n).
\]
We will frequently identify a dynamical system with its generating map.

\begin{example}
  Perhaps the oldest application of discrete dynamical systems is the study of population dynamics, which goes back at least to the thirteenth century with Fibonacci. But the Fibonacci sequence predicts unbounded population growth; due to resource limits, this is not observed in reality. To find a more realistic model, first assume a difference equation of the form
  \[
    \tilde{x}_{n + 1} = g\parens{\tilde{x}_n}\tilde{x}_n.
  \]
  The (as of yet undetermined) function \(g\) represents the per-capita growth rate of the population; that is, for each individual in generation \(n\), there will be \(g\parens{\tilde{x}_n}\) individuals in generation \(n + 1\). The preceding observation about resource limits suggests that \(g\parens{\tilde{x}_n}\) should be a decreasing function. The simplest way to do this is to make \(g\) linear; e.g.,
  \[
    \tilde{x}_{n + 1} = \parens{r - c\tilde{x}_n}\tilde{x}_n,
  \]
  where \(r\) is the rate of reproduction and \(c > 0\) is the strength of competition. If we nondimensionalize by making the substitution \(x_n = \frac{c}{r}\tilde{x}_n\), we obtain the \emph{logistic model}
  \[
    x_{n + 1} = rx_n(1 - x_n).
  \]
  in its canonical form.
  We need to ensure that the model is valid; in particular, we need to avoid nonsensical negative populations. It is easily seen that, assuming \(r \ne 0\), the map \(x \mapsto rx(1 - x)\) is a quadratic polynomial with roots at \(x = 0\) and \(x = 1\), which will always be negative somewhere. We expect a positive rate of reproduction, so we impose \(r > 0\) and take the domain of the map to be \([0, 1]\). We then need to ensure \(x_{n + 1} \in [0, 1]\). For this, it suffices to ensure that the unique maximum at \(x = \frac{1}{2}\) lies within \([0, 1]\), which requires \(r \le 4\).
\end{example}

\begin{example}
  The fact that the parameter \(r\) of the logistic map cannot exceed \(4\) seems like an arbitrary limitation. The cause of the problem is that the per-capita growth function \(g\) eventually becomes negative; therefore, we need to find a per-capita growth function that is nonnegative everywhere. The obvious thing to do is to find a function that has a horizontal asymptote approaching zero from above. The function should be finite on \(\rhalfopen{0, \infty}\), so something like \(x^{-a}\) is out. Instead, the simplest possible example is something like \(e^{-x}\). Properly parameterized, this is
  \[
    g(\tilde{x}) = \exp(r - a\tilde{x}),
  \]
  which yields the model
  \[
    \tilde{x}_{n + 1} = \tilde{x}_{n}\exp(r - a\tilde{x}_{n}).
  \]
  We can again nondimensionalize by letting \(x_n = a\tilde{x}_n\), obtaining the \emph{Ricker model}
  \[
    x_{n + 1} = x_n\exp(r - x_n).
  \]
  Note that the model is valid for any value of \(r\), and that we can take the domain to be \(\rhalfopen{0, \infty}\).
\end{example}

Throughout this section, we will develop the basic analysis of these two models.

The fundamental problem in the study of discrete dynamical systems is to determine long-term behavior under iteration. That is, given a set \(X\) and a map \(f : X \to X\), we seek to characterize \(\set{f^n(x)}\) for all \(x \in X\).

\begin{definition}
  Let \(X\) be a set, \(f : X \to X\), and \(x \in X\). The \emph{orbit} or \emph{trajectory} of \(x\) under \(f\) is \(\orbit{x} = \set{f^n(x)}\), considered either as a sequence or as a set depending on context.
\end{definition}

The fundamental \emph{obstacle} in the study of discrete dynamical systems is the fact that it is almost always impossible to give a closed-form solution for \(f^n(x)\). (Even in the very simple case of the logistic map, closed-form solutions exist only for \(r = 2\) and \(4\).) Therefore, we are usually forced to study orbits as objects in their own right. The first step is the study of fixed points.

\begin{definition}
  Let \(X\) be a set and \(f : X \to X\). A point \(x \in X^*\) is called a \emph{fixed point}, \emph{equilibrium point}, or \emph{stationary point} of \(f\) if \(f(x^*) = x^*\). Equivalently, \(x^*\) is a fixed point of \(f\) if \(\orbit{x^*} = \set{x^*}\).
\end{definition}

\begin{example}
  The fixed points of the logistic map can be found by solving
  \[
    \begin{aligned}
      rx(1 - x) = x
      &\iff rx^2 + (1 - r)x = 0
      \\
      &\iff x = 0 \text{ or } 1 - \frac{1}{r}.
    \end{aligned}
  \]
  At \(x = 0\), the population has no members, so it cannot grow or shrink due to reproduction or death. At \(x = 1 - \frac{1}{r}\), the opposing forces of reproduction and competition are in equilibrium. Note that the equilibrium fixed point only exists in the domain \([0, 1]\) if \(r \ge 1\); furthermore, if \(r = 1\), the two fixed points coincide.
\end{example}

\begin{example}
  The fixed points of the Ricker map are given by the solutions to
  \[
    x\exp(r - x) = x.
  \]
  \(x = 0\) is again a solution; the other is
  \[
    \begin{aligned}
      \exp(r - x) = 1
      &\iff
      r - x = 0
      \\
      &\iff
      x = r.
    \end{aligned}
  \]
  So, again, we end up with an extinction fixed point and an equilibrium fixed point. The equilibrium fixed point only exists in the domain \(\rhalfopen{0, \infty}\) if \(r \ge 0\); and if \(r = 0\), the two fixed points coincide.
\end{example}

The importance of fixed points comes from the fact that the long-term behavior of a map can often be given in terms of its fixed points.

\begin{theorem}\label{theorem:iteration-limit-iff-fixed-point}
  Let \(X\) be a Hausdorff space, \(f : X \to X\) continuous, and \(x^* \in X\). Then \(x^*\) is a fixed point of \(f\) if and only if there exists some \(x \in X\) such that \(f^n(x) \to x^*\).
\end{theorem}
\begin{proof}
  Suppose \(f^n(x) \to x^*\). Since \(f\) is continuous, \(f\parens{f^n(x)} \to f(x^*)\). But \(\set{f\parens{f^n(x)}} = \set{f^{n + 1}(x)}\), which has the same convergence behavior as \(\set{f^n(x)}\). Therefore, \(f\parens{f^n(x)} \to x^*\). Since \(X\) is Hausdorff, \(f\) can have at most one limit, so we obtain \(f(x^*) = x^*\) as desired. For the other direction, simply note that if \(x^*\) is a fixed point of \(f\), then \(f^n(x^*) \to x^*\).
\end{proof}

\begin{definition}
  Let \(X\) be a Hausdorff space, \(f : X \to X\) continuous, and \(x^* \in X\) a fixed point of \(f\).
  \begin{itemize}
  \item \(x^*\) is \emph{(locally) stable} if, for all open sets \(U \subseteq X\) such that \(x^* \in U\), there exists an open set \(V \subseteq U\) such that \(x \in V\) implies \(f^n(x) \in U\) for all \(n \in \naturals\).
  \item \(x^*\) is \emph{(locally) attracting} if there exists an open set \(U \subseteq X\) with \(x^* \in U\) such that \(x \in U\) implies \(f^n(x) \to x^*\).
  \item \(x^*\) is \emph{(locally) asymptotically stable} if it is locally both stable and attracting.
  \item \(x^*\) is \emph{globally asymptotically stable} if it is stable and \(f^n(x) \to x^*\) for all \(x \in X\).
  \end{itemize}
\end{definition}

Roughly speaking, \(x^*\) is stable if points sufficiently near to \(x^*\) do not wander too far from \(x^*\) under iteration, and \(x^*\) is attracting if points sufficiently near to \(x^*\) converge to \(x^*\) under iteration.

Note that we may speak of global stability in a slightly looser sense: we will sometimes say that a fixed point is globally asymptotically stable if it attracts everything except any other fixed points that may exist.

A major problem in the study of discrete dynamical systems, and one we will return to, is that it is often much easier to prove local stability than global stability. Global stability \emph{always} requires global information; but, as the following theorems and examples show, local stability usually requires only local information.

\begin{definition}
  Let \(U \subseteq \reals\) be open and \(f : U \to U\) differentiable at a fixed point \(x^* \in U\). If \(\abs{f'(x^*)} \ne 1\), then \(f\) is \emph{hyperbolic}; otherwise, \(f\) is \emph{nonhyperbolic}.
\end{definition}

\begin{theorem}
  Let \(U \subseteq \reals\) be open and \(f : U \to U\) continuously differentiable at a hyperbolic fixed point \(x^* \in U\).
  \begin{enumerate}
  \item If \(\abs{f'(x^*)} < 1\), then \(x^*\) is asymptotically stable.
  \item If \(\abs{f'(x^*)} > 1\), then \(x^*\) is unstable.
  \end{enumerate}
\end{theorem}

\begin{example}
  The derivative of the logistic map is
  \[
    x \mapsto r(1 - 2x).
  \]
  The extinction fixed point \(x = 0\) is asymptotically stable as long as \(r < 1\). This is expected: if the size of each successive generation is lower than that of the preceding generation, the population should go extinct. Note, though, that we have not quite shown this: we have only shown that \(x = 0\) is \emph{locally} asymptotically stable.

  Continuing the analysis, the equilibrium fixed point \(x = 1 - \frac{1}{r}\) is asymptotically stable as long as \(\abs{r - 2} < 1\), which is to say \(1 < r < 2\).
\end{example}

\begin{example}
  The derivative of the Ricker map is
  \[
    x \mapsto (1 - x)\exp(r - x).
  \]
  The extinction fixed point \(x = 0\) is asymptotically stable if \(\abs{\exp(r)} < 1\), which is to say \(r < 0\). The equilibrium fixed point \(x = r\) is asymptotically stable as long as \(\abs{r - 1} < 1\), which is to say \(0 < r < 2\).
\end{example}

The preceding analysis has some nonhyperbolic holes. For example, we have not said whether the single fixed point of the logistic map with \(r = 1\) is stable.

\begin{theorem}\label{theorem:derivative-1-stability}
  Let \(U \subseteq \reals\) be open and \(f : U \to U\) thrice continuously differentiable at a fixed point \(x^* \in U\) such that \(f'(x^*) = 1\).
  \begin{enumerate}
  \item If \(f''(x^*) \ne 0\), then \(x^*\) is unstable.\footnote{In fact, \(x^*\) is \emph{semistable}, which essentially means that it is stable and attracting only on either the left or the right.}
  \item If \(f''(x^*) = 0\) and \(f'''(x^*) > 0\), then \(x^*\) is unstable.
  \item If \(f''(x^*) = 0\) and \(f'''(x^*) < 0\), then \(x^*\) is asymptotically stable.
  \end{enumerate}
\end{theorem}

\begin{example}
  The second derivative of the logistic map is
  \[
    x \mapsto -2r.
  \]
  Thus, all nonhyperbolic fixed points of the logistic map are asymptotically stable. Specifically, when \(r = 1\), the single fixed point is stable; and when \(r = 2\), the equilibrium fixed point is stable.
\end{example}

\begin{example}
  The second derivative of the Ricker map is
  \[
    x \mapsto (x - 2)\exp(r - x).
  \]
  With \(r = 0\), the value of the derivative at \(x = 0\) is \(-2\), so the single fixed point is stable. With \(r = 2\), the value of the derivative at \(x = r = 2\) is \(0\), so we compute the third derivative as
  \[
    x \mapsto (3 - x)\exp(r - x).
  \]
  Then the value of the third derivative at \(x = r = 2\) is \(0\), so \cref{theorem:derivative-1-stability} tells us nothing.
\end{example}

Only one hole remains: the stability of the equilibrium fixed point of the Ricker map when \(r = 2\). For this, we need one final theorem.

\begin{definition}
  Let \(U \subseteq \reals\) be open and \(f : U \to \reals\). Then, wherever \(f\) is thrice-differentiable, the \emph{Schwarzian derivative} of \(f\) is
  \[
    \schwarzian{f}(x) = \frac{f'''(x)}{f'(x)} - \frac{3}{2}\parens{\frac{f''(x)}{f'(x)}}^2.
  \]
\end{definition}

\begin{theorem}
  Let \(U \subseteq \reals\) be open and \(f : U \to U\) thrice continuously differentiable at a fixed point \(x^* \in U\) such that \(f'(x^*) = -1\).
  \begin{enumerate}
  \item If \(\schwarzian{f(x^*)} < 0\), then \(x^*\) is asymptotically stable.
  \item If \(\schwarzian{f(x^*)} > 0\), then \(x^*\) is unstable.
  \end{enumerate}
\end{theorem}

\begin{example}
  The Schwarzian derivative of the Ricker map is
  \[
    -\frac{x^2 - 4x + 6}{x^2 - 2x + 1}
  \]
  the value of which does not depend on \(r\). At \(x = 2\), its value is \(-1\), so the equilibrium fixed point is asymptotically stable for \(r = 2\).
\end{example}

Now we have completely determined the local stability properties of the fixed points of the logistic and Ricker maps. To summarize:
\begin{itemize}
\item For the logistic map:
  \begin{itemize}
  \item the extinction fixed point is asymptotically stable exactly when \(r \in \lhalfopen{0, 1}\), and
  \item the equilibrium fixed point is asymptotically stable exactly when \(r \in [1, 2]\).
  \end{itemize}
\item For the Ricker map:
  \begin{itemize}
  \item the extinction fixed point is asymptotically stable exactly when \(r \le 0\), and
  \item the equilibrium fixed point is asymptotically stable exactly when \(r \in [0, 2]\).
  \end{itemize}
\end{itemize}
But recall that the study of fixed points is a means to the end of determining the long-term behavior of the phase space under iteration. And while we now know where in parameter space the fixed points of our two maps are attracting, we do not know where they are attracting in phase space (except that, when they are stable, they at least attract a neighborhood). Thus, in a sense, we have not learned much.

Unfortunately, there is no general procedure for determining the largest set that a given fixed point attracts. In fact, \emph{a priori}, it is difficult to even form a conjecture. This is where technology comes in: we can obtain good guesses by visual inspection of how a map behaves under iteration.

% \set{theorem}\label{theorem:monotone-convergence}
%   Let \(X\) be a totally ordered complete Hausdorff space, \(f : X \to X\) continuous and strictly increasing, and \(x^* \in X\) a fixed point of \(f\) such that \(f(x) > x\) for \(x < x^*\) and \(f(x) < x\) for \(x > x^*\). Then \(x^*\) is globally asymptotically stable.
% \end{theorem}
% \begin{proof}
%   Let \(x \in X\). If \(x < x^*\), then \(f(x) < f(x^*) = x^*\). It follows by induction that the sequence \(\set{f^n(x)}\) never exceeds \(x^*\). Since \(f(x) > x\) for \(x < x^*\), the sequence is also increasing, so it converges. By \cref{theorem:iteration-limit-iff-fixed-point}, the sequence must converge to a fixed point. But the hypotheses guarantee that \(x^*\) is the only fixed point of \(f\), so \(f^n(x) \to x^*\). The case \(x > x^*\) is similar.
% \end{proof}

% \begin{example}
%   The logistic map \(x \mapsto rx(1 - x)\) is not strictly increasing. However, it is strictly increasing on \(\bracks*{0, \frac{1}{2}}\); and if \(1 < r \le 2\), then the nonzero fixed point \(1 - \frac{1}{r}\) lies in the interval \(\lhalfopen*{0, \frac{1}{2}}\), so the hypotheses of \cref{theorem:monotone-convergence} are satisfied, and the nonzero fixed point is asymptotically stable on \(\lhalfopen*{0, \frac{1}{2}}\). Furthermore, the image of \(\parens*{\frac{1}{2}, 1}\) is \(\parens*{0, \frac{r}{4}}\). If \(r \le 2\), this is a subset of \(\parens*{0, \frac{1}{2}}\), so the logistic map is asymptotically stable on \((0, 1)\). Since \(0\) is fixed and \(1 \mapsto 0\), this completely describes the dynamics of the logistic map for \(1 < r \le 2\).
% \end{example}

\subsection{Two-Dimensional Maps}

The study of planar maps in general begins with the study of \emph{linear} planar maps. Let \(L\) be a linear operator; then \(L\) always has at least one fixed point: the origin. In the case of a two-dimensional operator, we can characterize the stability of the origin in terms of the spectral radius \(\rho(L)\).

\begin{theorem}
  Let \(L : \reals^2 \to \reals^2\) be linear.
  \begin{enumerate}
  \item If \(\rho(L) < 1\), then the origin is globally asymptotically stable.
  \item If \(\rho(L) > 1\), then the origin is unstable.
  \item If \(\rho(L) = 1\), then the origin is unstable if \(L\) has Jordan form \(\begin{bmatrix} \lambda & 1 \\ 0 & \lambda \end{bmatrix}\), and stable otherwise.
  \end{enumerate}
\end{theorem}

The significance of this theorem lies in the fact that if \(f : \reals^2 \to \reals^2\) is continuously differentiable and \(x^* \in \reals^2\) is fixed under \(f\), then \(f\) is locally conjugate (via the Jacobian \(\jacobian{f}\)) to a linear map at \(x^*\).

\begin{theorem}
  Let \(U \subseteq \reals^2\) be open, \(f : U \to U\) a \(C^1\) map, and \(x^* \in U\) fixed under \(f\). Write \(L = \jacobian{f}(x^*)\).
  \begin{enumerate}
  \item If \(\rho(L) < 1\), then \(x^*\) is asymptotically stable.
  \item If \(\rho(L) > 1\), then \(x^*\) is unstable
  \item If \(\rho(L) = 1\), then \(x^*\) may be stable or unstable.
  \end{enumerate}
\end{theorem}

\begin{example}
  The main focus of this thesis is the \emph{planar Ricker model}
  \[
    \begin{bmatrix}
      x_{n + 1} \\ y_{n + 1}
    \end{bmatrix}
    =
    \begin{bmatrix}
      x_{n}\exp(r - x_n - ay_n)
      \\
      y_{n}\exp(s - y_n - bx_n)
    \end{bmatrix}.
  \]
  This is a generalization of the one-dimensional Ricker model in the sense that the entire one-dimensional Ricker model lives on the \(x\)- and \(y\)-axes. That is, if \(x_n = 0\), then the model reduces to the one-dimensional Ricker model on the \(y\)-axis; and if \(y_n = 0\), the model reduces to the one-dimensional Ricker model on the \(x\)-axis. Thus, all of the fixed points from the one-dimensional model are embedded in the two-dimensional model: there is an extinction fixed point at \((0, 0)\) and two exclusion fixed points at \((r, 0)\) and \((0, s)\). To find a fourth fixed point, solve
  \[
    \begin{aligned}
      \begin{bmatrix}
        1
        \\
        1
      \end{bmatrix}
      =
      \begin{bmatrix}
        \exp(r - x - ay)
        \\
        \exp(s - y - bx)
      \end{bmatrix}
      &\iff
      \begin{bmatrix}
        1 & a
        \\
        b & 1
      \end{bmatrix}
      \begin{bmatrix}
        x
        \\
        y
      \end{bmatrix}
      =
      \begin{bmatrix}
        r
        \\
        s
      \end{bmatrix}
      \\
      &\iff
      \begin{bmatrix}
        x
        \\
        y
      \end{bmatrix}
      =
      \frac{1}{1 - ab}
      \begin{bmatrix}
        r - as
        \\
        s - br
      \end{bmatrix}.
    \end{aligned}
  \]
  So the coexistence fixed point is
  \[
    \parens{\frac{r - as}{1 - ab}, \frac{s - br}{1 - ab}},
  \]
  and it exists as long as \(ab \ne 1\). The map has Jacobian
  \[
    \begin{bmatrix}
      (1 - x)\exp(r - x - ay) & -ax\exp(r - x - ay)
      \\
      -by\exp(s - y - bx) & (1 - y)\exp(s - y - bx)
    \end{bmatrix}.
  \]
\end{example}

\section{GPGPU and CUDA}

The ``brain'' of a computer is its \emph{central processing unit}, or CPU.\@ Modern CPUs are typically optimized for serial performance and low latency. This is ideal for applications such as compiling programs and serving webpages, but it is less well-suited for applications that involve performing homogeneous operations on large datasets. Most computational tasks in discrete dynamical systems fall into this category. For example, to generate a bifurcation diagram for a map \(f\), one typically iterates \(f\) some number of times \(n\) (usually in the hundreds or thousands) over a large number of parameter values. In the serial model that most CPUs are optimized for, this happens one parameter value at a time: one computes \(\setbuilder{f_a^n(x)}{0 \le x < n}\) for \(a = a_1\), then for \(a = a_2\), and so on.

In the last decade, as the serial paradigm has hit a performance plateau, CPUs have increased their theoretical throughput performance by incorporating more computing cores, which can perform operations independently of each other; but core numbers remain small compared to dataset sizes. For example, each node in the Trinity University high performance computing (HPC) cluster has two Intel Xeon ES-2695 v4, each of which has 18 cores. This is near the high end of core counts for non-supercomputing chips,\footnote{Or, at least, it \emph{was}: on February 7, AMD released the 64-core Threadripper 3990x.} but it is still a factor of 100 below the number of parameter samples required to create an acceptable bifurcation diagram for a one-dimensional map.

Also in the last decade, and partly by coincidence, a new computing paradigm has come to prominence. In the late 1990s and early 2000s, demand for real-time three-dimensional graphics in video games began to outstrip available computing power. The solution came in the form of the \emph{graphics processing unit}, or GPU.\@ As real-time three-dimensional graphics requires processing a large amount of data (typically vertices or pixels) in a homogeneous and independent manner, GPUs incorporate large numbers of computing cores capable of running in parallel. It was soon discovered that this hardware model had uses in other domains, such as scientific computing. And although it was cumbersome to write linear algebra programs in terms of graphics primitives, general-purpose programming frameworks soon arose. Thus, general-purpose GPU (GPGPU) programming was born.

Given the potential for GPUs to accelerate computations in discrete dynamical systems, why aren't they widespread yet? The main answer is that writing a well-optimized GPU kernel is harder than simply writing a program to run on the CPU as usual. There are several reasons for this. The two biggest GPGPU frameworks --- Nvidia's CUDA and the open standard OpenCL --- natively support only C and C++, which are more difficult to program in than memory-managed languages such as Java, Python, Maple, Mathematica, R, etc.\footnote{Bindings for other languages are available, but they typically perform below the native versions by a factor of at least 2.} And, even within C/C++, a CUDA/OpenCL cannot be written in exactly the same way as a normal C/C++ program: the kernel must ``hook into'' the GPU framework, it must be optimized differently from a CPU program, and it generally cannot use available libraries that have not been also been written in the same GPGPU framework. That last point is especially important when network effects are taken into account: the fewer libraries that have been written for a GPGPU framework, the harder it is to write a new library for that GPGPU framework.\footnote{Conversely, the more libraries that have been written, the easier it becomes to write a new library --- presumably up to some saturation point. Does the number of libraries follow a logistic or Ricker trend?} The situation has improved somewhat with the growing popularity of artificial neural networks (another domain where GPUs tend to outperform CPUs), but a gap remains.

The other side of the equation is the fact that, for most applications, the performance gains of GPGPU would not make up for the lost productivity due to the greater difficulty of GPU programming. For example, although a typical CPU has many fewer cores than parameter samples needed to create a bifurcation diagram in one dimension, modern CPUs are so fast that it simply doesn't matter. But the picture changes when we move to two dimensions, where increasing the resolution (sample density) of a bifurcation diagram by a factor of \(n\) requires increasing the number of samples by a factor of \(n^2\), which quickly becomes infeasible on a CPU.\@ And, as we will see, a high sample density is crucial to obtaining a good picture of the period-doubling route to chaos. So the time has come to dip our toes into new technology.

Thus, a major component of this thesis is \texttt{ndyn}, a CUDA-powered library for discrete dynamical systems in \emph{n} dimensions. The library is, as is to be expected, far from complete; but all the new visualizations contained in this thesis were created using it.

% (For example, each GPU-focused node in the Trinity University HPC cluster has two Nvidia Tesla K80m, each of which has 4992 cores.)

% new computing paradigms have come to prominence. Before the late 1990s, the graphical complexity of three-dimensional video games was limited by the performance of the CPU.\@ To solve this problem, Nvidia released the first modern graphics processing unit, or GPU, in 1999. Real-time graphics processing involves performing a set of comparatively simple homogeneous operations on a large dataset, such as mesh vertices or pixels; and this happens to be the same sort of application   so as GPUs grew in power, they came to fill a niche that CPUs were falling behind in.

\end{document}